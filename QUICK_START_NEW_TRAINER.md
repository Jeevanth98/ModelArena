# ğŸ¯ Quick Start: New Data-Leakage-Free Training

## âœ… What Was Fixed

**CRITICAL BUG FOUND & FIXED:**
- âŒ **Old script (`train_cv.py`)**: Splits frames randomly â†’ Same video's frames in both train & validation
- âœ… **New script (`train_single_split.py`)**: Splits entire videos â†’ No overlap between train & validation

**Impact:** The old script gave **artificially high** validation scores (0.98+) because the model saw different frames from the same videos during training and validation. The new script gives **realistic** scores (0.92-0.95) that actually reflect performance on unseen videos.

---

## ğŸš€ For Colab: Stop Current Training & Restart

### Step 1: Stop Your Current Training

In Colab, press the **Stop button (â– )** on your training cell. Your current models have data leakage.

### Step 2: Pull Latest Code

```python
import os
os.chdir('/content/ModelArena')

# Pull the fixed code from GitHub
!git pull origin main

# Verify new file exists
!ls -la src/train_single_split.py
```

### Step 3: Train with NEW Script (No Data Leakage!)

```python
from src.train_single_split import SingleSplitTrainer

# Initialize trainer with 70:30 split (prevents data leakage)
trainer = SingleSplitTrainer(
    model_name='xception',
    train_split=0.7,           # 70% train, 30% validation
    num_epochs=30,
    batch_size=32,
    learning_rate=1e-4,
    device='cuda',
    output_dir='models/xception_70_30_no_leakage',
    early_stopping_patience=7,
    use_focal_loss=True,
    use_mixup=True,
    input_channels=3,
    random_seed=42
)

# Train (only takes ~1 hour vs 4-5 hours with CV!)
results = trainer.train(
    metadata_file='data/processed/preprocessing_metadata.json',
    data_root='data/processed'
)

# The script will automatically:
# 1. Split videos (not frames) into 70% train / 30% validation
# 2. Verify NO data leakage
# 3. Train 1 model (faster than 5-fold CV)
# 4. Save best model when validation improves

print(f"\nâœ… Training Complete!")
print(f"Best AUC-ROC: {results['best_auc']:.4f}")
print(f"Best Epoch: {results['best_epoch']}")
```

### Step 4: Backup Model to Google Drive

```python
# Mount Drive
from google.colab import drive
drive.mount('/content/drive')

# Copy model to Drive
!mkdir -p /content/drive/MyDrive/ModelArena_Fixed_Models
!cp -r models/xception_70_30_no_leakage/* /content/drive/MyDrive/ModelArena_Fixed_Models/

print("âœ… Model backed up to Google Drive!")
```

---

## ğŸ“Š What You'll See (Console Output)

```
======================================================================
Creating Video-Level Split (Prevents Data Leakage)
======================================================================
Total videos: 600
  Real: 300
  Fake: 300

Train Set:
  Videos: 420 (Real: 210, Fake: 210)
  Frames: 6720

Validation Set:
  Videos: 180 (Real: 90, Fake: 90)
  Frames: 2880

âœ… Video-level split ensures NO DATA LEAKAGE
   (All frames from same video stay in same split)
======================================================================

======================================================================
Data Leakage Check
======================================================================
Train videos: 420
Val videos: 180
Overlapping videos: 0

âœ… NO DATA LEAKAGE - All videos properly separated
======================================================================

Starting Training...

Epoch 1/30
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Learning Rate: 0.000100
Train Loss: 0.3456 | Val Loss: 0.2345
Val Accuracy: 0.8923 | Val AUC-ROC: 0.9234
âœ“ Best model saved (AUC-ROC: 0.9234)
Epoch Time: 123.4s

Epoch 2/30
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
...
```

---

## â±ï¸ Training Time Comparison

| Method | Models | Time | Data Leakage | Recommended |
|--------|--------|------|--------------|-------------|
| Old 5-Fold CV | 5 models | ~4-5 hours | âŒ YES | âŒ NO |
| New 70:30 Split | 1 model | ~1 hour | âœ… NO | âœ… YES |

**Result:** 5Ã— faster training + no data leakage + simpler inference!

---

## ğŸ¯ For Inference (After Training)

The inference code stays **exactly the same**, just point to the new model:

```python
from src.inference import EnsemblePredictor

# Load the single trained model
model_configs = [{
    'model_name': 'xception',
    'checkpoint_path': 'models/xception_70_30_no_leakage/xception_best.pth',
    'input_channels': 3,
    'weight': 1.0
}]

predictor = EnsemblePredictor(
    model_configs=model_configs,
    device='cuda',
    use_tta=True,
    tta_num_augmentations=5
)

# Predict on test videos (same as before)
# ... rest of inference code unchanged
```

---

## ğŸ“ˆ Expected Performance (Realistic)

### With Data Leakage (Old):
- Validation AUC-ROC: **0.98-0.99** âŒ (Too good to be true!)
- Test Set AUC-ROC: **0.85-0.90** (Reality check)
- Gap: **~10-15%** (Overfitting indicator)

### Without Data Leakage (New):
- Validation AUC-ROC: **0.92-0.95** âœ… (Realistic!)
- Test Set AUC-ROC: **0.90-0.93** (Close to validation)
- Gap: **~2-3%** (Good generalization)

**Don't worry if validation scores are lower!** This is expected - they now reflect **true performance on unseen videos**.

---

## ğŸ¤” FAQ

**Q: Should I retrain from scratch?**  
A: **YES!** Your current models have data leakage and will perform poorly on test data.

**Q: Will my accuracy go down?**  
A: Validation accuracy will be **more realistic** (lower than inflated leaky scores), but **test accuracy will improve** because the model generalizes better.

**Q: Can I still use 5-fold CV?**  
A: Yes, but fix the splitting (see [DATA_LEAKAGE_FIX.md](DATA_LEAKAGE_FIX.md)). For your hackathon, the 70:30 split is faster and simpler.

**Q: Do I need to reprocess videos?**  
A: **NO!** Preprocessing is fine. Only training needs to change.

**Q: What about my old trained models?**  
A: They have data leakage - don't use them for final submission. Train new ones with the fixed script.

---

## âœ… Summary

1. **Stop** current training (has data leakage)
2. **Pull** latest code: `!git pull origin main`
3. **Use** new script: `train_single_split.py`
4. **Train** 1 model in ~1 hour (vs 5 hours)
5. **Get** realistic validation scores
6. **Win** hackathon with properly generalized model! ğŸ†

Read [DATA_LEAKAGE_FIX.md](DATA_LEAKAGE_FIX.md) for detailed technical explanation.
